{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows you to change source code of modules without reruning everything\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Random_Forest_module import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following data manipulations are based on work in the Pima EDA notebook.  Certain aspects to explore could be feature engineering that was not explored in this part of the project since the main aim was to build a BRAF algorithm rather than to optimize it.  Creating categorical variables based on insulin levels, BMI, and/or age could be explored to improve the alogirthms predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('diabetes.csv')\n",
    "df = df_raw.copy()\n",
    "print(df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill cells with a value of 0 as NAN\n",
    "\n",
    "df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values with the median value for that variable\n",
    "\n",
    "cols = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\n",
    "for i in cols:\n",
    "    df[i].fillna((df[i].median()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the units of insulin in this dataset and our knowledge of reasonable 2-Hour serum insulin (mu U/ml) ranges\n",
    "# we can either remove these data or set them to be the upper limit of the 85th percentile, which is ~320\n",
    "# since we don't have much data we suppress these values rather than removing them\n",
    "\n",
    "Q1 = df.Insulin.quantile(0.15)\n",
    "Q3 = df.Insulin.quantile(0.85)\n",
    "IQR = Q3-Q1\n",
    "ins_lower = Q1 - 1.5*IQR\n",
    "ins_upper = Q3 + 1.5*IQR\n",
    "\n",
    "print(ins_upper)\n",
    "df.loc[df[\"Insulin\"] > ins_upper,\"Insulin\"] = ins_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that our distributions match those in the EDA notebook\n",
    "\n",
    "fig, ax = plt.subplots(4,2, figsize=(15,13))\n",
    "sns.distplot(df.Age, bins = 20, ax=ax[0,0]) \n",
    "sns.distplot(df.Pregnancies, bins = 20, ax=ax[0,1]) \n",
    "sns.distplot(df.Glucose, bins = 20, ax=ax[1,0]) \n",
    "sns.distplot(df.BloodPressure, bins = 20, ax=ax[1,1]) \n",
    "sns.distplot(df.SkinThickness, bins = 20, ax=ax[2,0])\n",
    "sns.distplot(df.Insulin, bins = 20, ax=ax[2,1])\n",
    "sns.distplot(df.DiabetesPedigreeFunction, bins = 20, ax=ax[3,0]) \n",
    "sns.distplot(df.BMI, bins = 20, ax=ax[3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80% training data and 20% testing data\n",
    "\n",
    "df_copy = df.copy()\n",
    "Train_set = df_copy.sample(frac=0.8, random_state=0)\n",
    "Test_set = df_copy.drop(Train_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set.reset_index(drop=True, inplace=True)\n",
    "Test_set.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set.shape, Test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = Train_set.columns\n",
    "x_cols = x_cols.drop('Outcome')\n",
    "y_cols = ['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train_set[x_cols]\n",
    "X_test = Test_set[x_cols]\n",
    "Y_train = Train_set[y_cols]\n",
    "Y_test = Test_set[y_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRAF and RF parameters\n",
    "\n",
    "S = 100 # total number of trees\n",
    "p = 0.5 # fraction of trees to use for BRAF\n",
    "K_NN = 10 # how many nearest neighbors to find for BRAF dataset\n",
    "base_tree_num = int(S*(1-p)) # how many trees go into the RF with the full dataset\n",
    "braf_tree_num = S-base_tree_num # how many trees go into the RF with the BRAF dataset\n",
    "\n",
    "num_feat = 'log2' # use log2 of the number of available features for each tree.  This speeds up computation time.\n",
    "depth = 10 # how many splits each tree can make (this is the default value)\n",
    "min_leaf = 3 # minimum amount of features a tree node should have in order to split\n",
    "k_folds = 10 # number of cross validation folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BRAF dataframe for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the majority and minority flags\n",
    "mincls = 1\n",
    "majcls = 0\n",
    "\n",
    "df_BRAF_train = get_BRAF_df(Train_set, y_cols[0], mincls, majcls, K_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_BRAF_train.shape)\n",
    "df_BRAF_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the BRAF training dataframe into X and Y\n",
    "\n",
    "X_braf_train = df_BRAF_train[x_cols]\n",
    "Y_braf_train = df_BRAF_train[y_cols]\n",
    "X_braf_train.shape, Y_braf_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Random Forest cross validation on the two training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CV for both the BRAF model\n",
    "\n",
    "y_pred_prob_train = get_cv_preds_braf(X_train, \n",
    "                                      Y_train, \n",
    "                                      X_braf_train, \n",
    "                                      Y_braf_train, \n",
    "                                      k_folds,\n",
    "                                      base_tree_num,\n",
    "                                      braf_tree_num, \n",
    "                                      num_feat, \n",
    "                                      depth, \n",
    "                                      min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metric scores for the combined models\n",
    "\n",
    "scores_train = get_cv_scores(y_pred_prob_train)\n",
    "scores_train_mean = np.mean(scores_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the metrics for the training dataset\n",
    "\n",
    "print('Cross validation metrics for the training data are:')\n",
    "print(f'Precision: {scores_train_mean[0]:.5f}')\n",
    "print(f'Recall: {scores_train_mean[1]:.5f}')\n",
    "print(f'AUROC: {scores_train_mean[2]:.5f}')\n",
    "print(f'AUPRC: {scores_train_mean[3]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PRC and ROC plots for the CV datasets\n",
    "\n",
    "plot_PRC(scores_train_mean[4],scores_train_mean[6],'Cross_Validation',scores_train_mean[3])\n",
    "plot_ROC(scores_train_mean[5],scores_train_mean[4],'Cross_Validation',scores_train_mean[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BRAF based on the training data using the same parameters as the cross validation\n",
    "\n",
    "braf = BiasedRandomForest(X_train, \n",
    "                          np.array(Y_train), \n",
    "                          X_braf_train, \n",
    "                          np.array(Y_braf_train), \n",
    "                          num_trees=base_tree_num, \n",
    "                          num_trees_braf=braf_tree_num, \n",
    "                          num_features=num_feat, \n",
    "                          depth=depth, \n",
    "                          min_leaf=min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and probabilities based on test data sets\n",
    "\n",
    "test_pred = braf.predict(X_test.values)\n",
    "test_prob = braf.predict_proba(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for the test data\n",
    "\n",
    "metrics = Metrics(np.array(np.squeeze(Y_test)) ,test_pred, np.array(test_prob)[:,1])\n",
    "\n",
    "# confusion matrix\n",
    "cm_test = metrics.compute_confusion_matrix()\n",
    "\n",
    "# precision and recall\n",
    "precision_test, recall_test, _ = metrics.calc_precision_recall(cm_test)\n",
    "\n",
    "# TPR, FPR, and 'precision rate'\n",
    "TPR_test, FPR_test, prec_test = metrics.calc_roc_prc()\n",
    "\n",
    "# AUPRC and AUROC\n",
    "AUPRC_test = metrics.AUC(TPR_test,prec_test)\n",
    "AUROC_test = metrics.AUC(FPR_test,TPR_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the metrics for the training dataset\n",
    "\n",
    "print('Metrics for the test data are:')\n",
    "print(f'Precision: {precision_test:.5f}')\n",
    "print(f'Recall: {recall_test:.5f}')\n",
    "print(f'AUROC: {AUROC_test:.5f}')\n",
    "print(f'AUPRC: {AUPRC_test:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PRC and ROC plots for the test datasets\n",
    "\n",
    "plot_PRC(TPR_test,prec_test,'Test_Dataset',AUPRC_test)\n",
    "plot_ROC(FPR_test,TPR_test,'Test_Dataset',AUROC_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
